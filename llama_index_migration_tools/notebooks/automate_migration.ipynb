{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a52fac3c-6ba1-485a-bb60-02715194a900",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index_migration_tools.main import main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a99b8d6-baa8-4baa-afe5-33575ad71c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d058217f-3258-4068-9341-77e93074f1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class cd:\n",
    "    \"\"\"Context manager for changing the current working directory\"\"\"\n",
    "    def __init__(self, newPath):\n",
    "        self.newPath = os.path.expanduser(newPath)\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.savedPath = os.getcwd()\n",
    "        os.chdir(self.newPath)\n",
    "\n",
    "    def __exit__(self, etype, value, traceback):\n",
    "        os.chdir(self.savedPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cfbbe4-8f38-485a-aa9d-b3b96ab5d725",
   "metadata": {},
   "source": [
    "### Get list of packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89dd48eb-50cb-4c25-add0-b9b8ecadfc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "IGNORE_LIST = [\n",
    "    \"__init__.py\",\n",
    "    \"__pycache__\",\n",
    "    \"loading.py\",\n",
    "    \"base.py\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3855ad25-ce8a-4eef-8788-019f4383a0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "kind = \"llms\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d6047f4a-6688-4473-b8ea-27766737ec1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "core_path = f\"/Users/nerdai/Projects/forks/llama_index/llama-index-core/llama_index/core/{kind}\"\n",
    "core = listdir(core_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee37bb49-546e-4d30-be82-02d1e399b2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "legacy_path = f\"/Users/nerdai/Projects/forks/llama_index/llama-index-legacy/llama_index/legacy/{kind}\"\n",
    "legacy = listdir(legacy_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8de2e949-f551-49ba-9ba5-83781badcd56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ai21.py',\n",
       " 'ai21_utils.py',\n",
       " 'anthropic.py',\n",
       " 'anthropic_utils.py',\n",
       " 'anyscale.py',\n",
       " 'anyscale_utils.py',\n",
       " 'azure_openai.py',\n",
       " 'bedrock.py',\n",
       " 'bedrock_utils.py',\n",
       " 'clarifai.py',\n",
       " 'cohere.py',\n",
       " 'cohere_utils.py',\n",
       " 'custom.py',\n",
       " 'everlyai.py',\n",
       " 'everlyai_utils.py',\n",
       " 'gemini.py',\n",
       " 'gemini_utils.py',\n",
       " 'generic_utils.py',\n",
       " 'gradient.py',\n",
       " 'huggingface.py',\n",
       " 'konko.py',\n",
       " 'konko_utils.py',\n",
       " 'langchain.py',\n",
       " 'langchain_utils.py',\n",
       " 'litellm.py',\n",
       " 'litellm_utils.py',\n",
       " 'llama_api.py',\n",
       " 'llama_cpp.py',\n",
       " 'llama_utils.py',\n",
       " 'llm.py',\n",
       " 'localai.py',\n",
       " 'mistral.py',\n",
       " 'mistralai_utils.py',\n",
       " 'mock.py',\n",
       " 'monsterapi.py',\n",
       " 'neutrino.py',\n",
       " 'nvidia_tensorrt.py',\n",
       " 'nvidia_tensorrt_utils.py',\n",
       " 'nvidia_triton.py',\n",
       " 'nvidia_triton_utils.py',\n",
       " 'ollama.py',\n",
       " 'openai.py',\n",
       " 'openai_like.py',\n",
       " 'openai_utils.py',\n",
       " 'openllm.py',\n",
       " 'openrouter.py',\n",
       " 'palm.py',\n",
       " 'perplexity.py',\n",
       " 'portkey.py',\n",
       " 'portkey_utils.py',\n",
       " 'predibase.py',\n",
       " 'replicate.py',\n",
       " 'rungpt.py',\n",
       " 'together.py',\n",
       " 'types.py',\n",
       " 'utils.py',\n",
       " 'vertex.py',\n",
       " 'vertex_gemini_utils.py',\n",
       " 'vertex_utils.py',\n",
       " 'vllm.py',\n",
       " 'vllm_utils.py',\n",
       " 'watsonx.py',\n",
       " 'watsonx_utils.py',\n",
       " 'xinference.py',\n",
       " 'xinference_utils.py']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_pass = sorted([el for el in legacy if el not in IGNORE_LIST])\n",
    "first_pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2e9167f2-751a-4287-b2af-301f4c2a50bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_ignore_files = {\n",
    "    \"embeddings\": [\n",
    "        \"multi_modal_base.py\",\n",
    "        \"utils.py\"\n",
    "    ],\n",
    "    \"llms\": [\n",
    "        \"llm.py\",\n",
    "        \"mock.py\",\n",
    "        \"types.py\",\n",
    "        \"utils.py\",\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2d67f848-6e53-4805-ab28-a54d76271733",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_removal_list = [el for el in first_pass if el not in additional_ignore_files[kind]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1d9ca4b8-1af4-4841-af75-5b379037c350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ai21.py',\n",
       " 'ai21_utils.py',\n",
       " 'anthropic.py',\n",
       " 'anthropic_utils.py',\n",
       " 'anyscale.py',\n",
       " 'anyscale_utils.py',\n",
       " 'azure_openai.py',\n",
       " 'bedrock.py',\n",
       " 'bedrock_utils.py',\n",
       " 'clarifai.py',\n",
       " 'cohere.py',\n",
       " 'cohere_utils.py',\n",
       " 'custom.py',\n",
       " 'everlyai.py',\n",
       " 'everlyai_utils.py',\n",
       " 'gemini.py',\n",
       " 'gemini_utils.py',\n",
       " 'generic_utils.py',\n",
       " 'gradient.py',\n",
       " 'huggingface.py',\n",
       " 'konko.py',\n",
       " 'konko_utils.py',\n",
       " 'langchain.py',\n",
       " 'langchain_utils.py',\n",
       " 'litellm.py',\n",
       " 'litellm_utils.py',\n",
       " 'llama_api.py',\n",
       " 'llama_cpp.py',\n",
       " 'llama_utils.py',\n",
       " 'localai.py',\n",
       " 'mistral.py',\n",
       " 'mistralai_utils.py',\n",
       " 'monsterapi.py',\n",
       " 'neutrino.py',\n",
       " 'nvidia_tensorrt.py',\n",
       " 'nvidia_tensorrt_utils.py',\n",
       " 'nvidia_triton.py',\n",
       " 'nvidia_triton_utils.py',\n",
       " 'ollama.py',\n",
       " 'openai.py',\n",
       " 'openai_like.py',\n",
       " 'openai_utils.py',\n",
       " 'openllm.py',\n",
       " 'openrouter.py',\n",
       " 'palm.py',\n",
       " 'perplexity.py',\n",
       " 'portkey.py',\n",
       " 'portkey_utils.py',\n",
       " 'predibase.py',\n",
       " 'replicate.py',\n",
       " 'rungpt.py',\n",
       " 'together.py',\n",
       " 'vertex.py',\n",
       " 'vertex_gemini_utils.py',\n",
       " 'vertex_utils.py',\n",
       " 'vllm.py',\n",
       " 'vllm_utils.py',\n",
       " 'watsonx.py',\n",
       " 'watsonx_utils.py',\n",
       " 'xinference.py',\n",
       " 'xinference_utils.py']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_removal_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b335bdf-ad4d-4556-8fab-de0cbef9faad",
   "metadata": {},
   "source": [
    "### Create packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "780509d3-8c7e-4e46-8382-071f0fc4a2c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/nerdai/Projects/forks/llama_index/llama-index-integrations/llms\n"
     ]
    }
   ],
   "source": [
    "extensions_path = f\"/Users/nerdai/Projects/forks/llama_index/llama-index-integrations/{kind}\"\n",
    "print(extensions_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "37c10a6f-ff93-4429-9680-d7c08fbb016b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess # just to call an arbitrary command e.g. 'ls'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "003ce426-ebb0-497a-b121-16a91b1dc9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ext in final_removal_list:\n",
    "    name = ext.replace(\".py\",\"\").replace(\"_\",\" \")\n",
    "    base_file = f\"{legacy_path}/{ext}\"\n",
    "    # enter the directory like this:\n",
    "    with cd(extensions_path):\n",
    "        main(integration_name=name, integration_type=kind, base_file=base_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e658fce7-0680-4884-811e-2729f9bfe0c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "migration-tools",
   "language": "python",
   "name": "migration-tools"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
